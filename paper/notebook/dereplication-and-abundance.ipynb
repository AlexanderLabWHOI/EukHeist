{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in assigned reads from Arianna's coverm run, allowing `coverm` to collapse dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder=\"/vortexfs1/omics/alexander/halexander/2020-tara-mag-abund/output_clustered_prok_euk\"\n",
    "initial_df = pd.read_csv(os.path.join(output_folder,'ERR1726699.coverm.abundance.tab'), \n",
    "                         sep='\\t', index_col=0)\n",
    "lengths = initial_df[\"ERR1726699_1.trimmed.fastq.gz Length\"].drop('unmapped')\n",
    "initial_df.columns = initial_df.columns.str.split(' ').str[1:].str.join('_')\n",
    "all_reads_new = pd.DataFrame(index = initial_df.index)\n",
    "for f in glob.glob(os.path.join(output_folder,'*tab')):\n",
    "    name = os.path.basename(f).split('.')[0]\n",
    "    if name == 'ERR1726706':\n",
    "        pass\n",
    "    else:\n",
    "        tt = pd.read_csv(f, sep='\\t', index_col=0)\n",
    "        tt.columns = tt.columns.str.split(' ').str[1:].str.join('_')\n",
    "        all_reads_new[name+\"_Reads\"] = tt['Read_Count']\n",
    "        all_reads_new[name] = tt['RPKM']\n",
    "all_reads_new= all_reads_new.drop('unmapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed = pd.concat([pd.read_csv('/vortexfs1/omics/alexander/halexander/2021-tara-final-paper/rename/renamed-eukaryotic-mags.tsv', sep='\\t'),\n",
    "                     pd.read_csv('/vortexfs1/omics/alexander/halexander/2021-tara-final-paper/rename/renamed-prokaryotic-mags.tsv', sep='\\t')])\n",
    "new_take=pd.wide_to_long(all_reads_new.loc[:,[curr for curr in all_reads_new.columns \\\n",
    "                                          if \"Reads\" not in curr]].reset_index(),\n",
    "                         stubnames=\"ERR\",i=\"Genome\",j=\"SampNum\").reset_index().\\\n",
    "    rename({\"ERR\":\"NewTake\"},axis=\"columns\")\n",
    "all_reads_reads=all_reads_new.loc[:,[curr for curr in all_reads_new.columns \\\n",
    "                                          if \"Reads\" in curr]].reset_index()\n",
    "all_reads_reads.columns=[curr.split(\"_Reads\")[0] for curr in all_reads_reads.columns]\n",
    "new_take_reads=pd.wide_to_long(all_reads_reads,\n",
    "                         stubnames=\"ERR\",i=\"Genome\",j=\"SampNum\").reset_index().\\\n",
    "    rename({\"ERR\":\"NewTake\"},axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get overall reads for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_counts = pd.DataFrame(columns = ['all_reads', 'trimmed_surviving'])\n",
    "with open('/vortexfs1/omics/alexander/halexander/2020-tara-mag-abund/trimmed-read-stats', 'r') as f:\n",
    "    for line in f:\n",
    "        l=line.split(':')\n",
    "        name = l[0].split('.')[0]\n",
    "        all_reads = int(l[2].strip().split(' ')[0])\n",
    "        trimmed_reads_surving_pairs = int(l[3].split(' ')[1])\n",
    "        read_counts.loc[name] = [all_reads_new, trimmed_reads_surving_pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_size = read_counts['trimmed_surviving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_reads = all_reads_new.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = total reads recruiting to a genome\n",
    "\n",
    "l = length of genome in Kb\n",
    "\n",
    "N = total number of trimmed reads in millions\n",
    "\n",
    "\\begin{align}\n",
    "RPKM_{i} & = \\frac{X_i}{l_i  N } * 10^9\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate RPKM from `coverm` run with clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = initial_df[\"Length\"].drop('unmapped')\n",
    "rename_lengths = pd.merge(lengths.reset_index(),renamed,left_on=\"Genome\",right_on=\"new_mag_name\")\n",
    "lengths_rpkm = pd.Series(list(rename_lengths[\"Length\"]),\n",
    "                         index=rename_lengths.new_mag_name)\n",
    "new_take_reads[\"Sample\"] = [\"ERR\"+str(curr) for curr in new_take_reads.SampNum]\n",
    "new_take_pivot = new_take_reads.merge(renamed,left_on=\"Genome\",right_on=\"new_mag_name\").\\\n",
    "                    pivot_table(values='NewTake', \n",
    "                                                                             index=['old_mag_name',\n",
    "                                                                                    'new_mag_name'],\n",
    "                    columns=['Sample']).reset_index()\n",
    "\n",
    "lengths_rpkm = lengths[list(new_take_pivot[\"new_mag_name\"])]\n",
    "rpkm_new_take_reads = (new_take_pivot.drop([\"old_mag_name\",\"new_mag_name\"],axis=1)).\\\n",
    "    div(library_size[new_take_pivot.drop([\"old_mag_name\",\"new_mag_name\"],axis=1).\\\n",
    "                     columns]).div(lengths_rpkm.reset_index(drop=True), axis=0)*1e9\n",
    "rpkm_new_take_reads[\"Genome\"] = new_take_pivot.new_mag_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPM is normalized to all total RPKM\n",
    "\\begin{align}\n",
    "TPM_{i} & = \\frac{RPKM_i}{\\sum RPKM} * 10^6\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed = pd.read_csv('/vortexfs1/omics/alexander/halexander/2021-tara-final-paper/rename/renamed-eukaryotic-mags.tsv', sep='\\t')\n",
    "rpkm_faceted = pd.wide_to_long(rpkm_new_take_reads.reset_index(),stubnames=\"ERR\",i=\"Genome\",j=\"SampNum\").\\\n",
    "    reset_index().rename({\"ERR\":\"Original\"},axis=\"columns\").merge(renamed,left_on=\"Genome\",right_on=\"old_mag_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_take[\"Sample\"] = [\"ERR\"+str(curr) for curr in new_take.SampNum]\n",
    "summed_rpkm = new_take.merge(renamed,left_on=\"Genome\",right_on=\"new_mag_name\").pivot_table(values='NewTake', \n",
    "                                                                             index=['old_mag_name',\n",
    "                                                                                    'new_mag_name'],\n",
    "                    columns=['Sample']).reset_index()\n",
    "selected = summed_rpkm.loc[:,[\"ERR\" in curr for curr in summed_rpkm.columns]]\n",
    "summed_rpkm = selected.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.DataFrame()\n",
    "for colname in selected.columns:\n",
    "    divided_res = (selected[colname]).div(summed_rpkm[colname])\n",
    "    final_df[colname]=divided_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm=final_df*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_names=new_take.merge(renamed,left_on=\"Genome\",right_on=\"new_mag_name\").pivot_table(values='NewTake', \n",
    "                                                                             index=['new_mag_name'],\n",
    "                    columns=['Sample']).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm[\"Genome\"]=for_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_take.merge(renamed,left_on=\"Genome\",right_on=\"new_mag_name\").pivot_table(values='NewTake', \n",
    "                                                                             index=['old_mag_name',\n",
    "                                                                                    'new_mag_name'],\n",
    "                    columns=['Sample']).reset_index().to_csv(os.path.join(\"../input/new_MAG_rpkm.csv\"))\n",
    "new_take.merge(renamed,left_on=\"Genome\",right_on=\"new_mag_name\").pivot_table(values='NewTake', \n",
    "                                                                             index=['old_mag_name',\n",
    "                                                                                    'new_mag_name'],\n",
    "                    columns=['Sample']).reset_index().to_csv(os.path.join(\"../input/new_MAG_tpm.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm.to_csv(os.path.join(\"..\",\"input\",\"MAG_tpm_new_approach.csv\"))\n",
    "\n",
    "new_take.merge(renamed,left_on=\"Genome\",right_on=\"new_mag_name\").pivot_table(values='NewTake', \n",
    "                                                                             index=['old_mag_name',\n",
    "                                                                                    'new_mag_name'],\n",
    "                    columns=['Sample']).reset_index().to_csv(os.path.join(\"..\",\"input\",\n",
    "                                                                          \"MAG_rpkm_new_approach.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scplotenv",
   "language": "python",
   "name": "scplotenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
